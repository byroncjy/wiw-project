{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to convert 1915 text into biographical dataset (csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 3.7.6\n",
    "import re # version 2.2.1\n",
    "import itertools\n",
    "import os\n",
    "import pandas as pd # version 1.0.1\n",
    "import csv # version 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collating all text files into one string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to ocr_split folder\n",
    "os.chdir(r\"C:\\Users\\byron\\Dropbox\\WIW\\1915_WIW\\ocr_split\")\n",
    "\n",
    "# create overall string\n",
    "segment = \"\"\n",
    "# omit first file, which is addenda\n",
    "for file in os.listdir()[1:]:\n",
    "    file_string = open(r\"{}\".format(file), \"r\", encoding=\"utf8\").read()\n",
    "    segment += file_string\n",
    "    \n",
    "# cleaning\n",
    "# remove redundant strings and certain non-ASCII chars\n",
    "for apos in [\"‘\", \"’\"]:\n",
    "    segment = segment.replace(apos, \"\\'\")\n",
    "\n",
    "for apos in [\"“\", \"”\"]:\n",
    "    segment = segment.replace(apos, \"\\\"\")\n",
    "\n",
    "segment = segment.replace(\"..\", \".\")\n",
    "segment = segment.replace(\"—\", \"-\")\n",
    "segment = segment.replace(\",,\", \",\")\n",
    "segment = segment.replace(\".:\", \";\")\n",
    "\n",
    "# any \"8\" surrounded by letters is usually an \"s\" or \"S\"\n",
    "def convert_eight_to_s(text):\n",
    "    text = re.sub(r\"(?<=[A-Z])8(?=[A-Z])\", \"S\", text)\n",
    "    text = re.sub(r\"(?<=[a-z])8(?=[a-z])\", \"s\", text)\n",
    "    text = re.sub(r\"(?<=[a-z])8\\b\", \"s\", text)\n",
    "    text = re.sub(r\"(?<=[A-Z]{2})8\", \"S\", text)\n",
    "    text = re.sub(r\"(?<=[a-z]{2})8\", \"s\", text)\n",
    "    text = re.sub(r\"8(?=[a-z]{2})\", \"S\", text)\n",
    "    text = re.sub(r\"8(?=[A-Z]{2})\", \"S\", text)\n",
    "    return text\n",
    "\n",
    "# run function twice: for 8 and 88\n",
    "segment = convert_eight_to_s(segment)\n",
    "segment = convert_eight_to_s(segment)\n",
    "# also convert \"8t\" to \"St\"\n",
    "segment = re.sub(r\"(?<=\\b)8(?=t)\", \"S\", segment)\n",
    "\n",
    "\n",
    "# \"O\" is commonly misrecognized as \"0\"\n",
    "segment = re.sub(r\"(?<=[A-Z])0(?=[A-Z])\", \"O\", segment)\n",
    "\n",
    "# \"S\" misrecognized as \"\"&\"\n",
    "segment = re.sub(r\"(?<=[A-Z])&(?=[A-Z])\", \"S\", segment)\n",
    "\n",
    "# correct certain misrecognized names\n",
    "segment = segment.replace(\"MAR LEY\", \"MARLEY\")\n",
    "segment = segment.replace(\"PiNN\", \"PINN\")\n",
    "segment = segment.replace(\"Jones, Grace\", \"JONES, Grace\")\n",
    "segment = segment.replace(\"Jackaon, William\", \"JACKAON, William\")\n",
    "segment = segment.replace(\"McCurdy, Theodore\", \"MCCURDY, Theodore\")\n",
    "segment = segment.replace(\"ABBOTT, Ebenezer Augustus, Jr.v writer, lecturer;\", \"ABBOTT, Ebenezer Augustus, Jr., writer, lecturer;\")\n",
    "\n",
    "# \"Digitized by...\" is often mixed in with actual text\n",
    "# make this case-insensitive\n",
    "phrases = [\"Who's Who of the Colored Race\", \"digitized by google\", \"digitized by\", \"digitized\"]\n",
    "for phrase in phrases:\n",
    "    pattern = re.compile(phrase, re.IGNORECASE) # some phrases are poorly recognized and will not be captured here\n",
    "    segment = pattern.sub(\"\", segment)\n",
    "\n",
    "for string in [\"-\\n\", \"_\\n\", \"«\", \"»\", \"•\", \"□\", \"°\", \"£\", \"\\t\", \"■\", \"™\", \"©\", \"®\", \"§\", \"►\", \"▲\", \"▼\", \"„\", \"€\", \"¥\", \"✓\", \"*\", \"#\", \"~\"]:\n",
    "    segment = segment.replace(string, \"\")\n",
    "\n",
    "segment = segment.replace(\"\\n\\n\", \"\\n\")\n",
    "segment = segment.replace(\"  \", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting string into biographical dataset per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\ufeff'}\n"
     ]
    }
   ],
   "source": [
    "# final check for non-ascii chars\n",
    "rem_ascii = re.findall(\"[^\\x00-\\x7F]\", segment)\n",
    "print(set(rem_ascii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1301\n",
      "                                                      0\n",
      "0     ABBOTT, Ebenezer Augustus, Jr., writer, lecturer;\n",
      "1     ABINGTON, George Sexton, principal public school;\n",
      "2                      ABNER, David, college president;\n",
      "3                              ADAMS, Luclen, druggist;\n",
      "4     ADAMS, Moses Samuel, insurance born at Greenvi...\n",
      "...                                                 ...\n",
      "1296                         YOUNG, George, bookseller;\n",
      "1297   YOUNG, Isaac Wilhelm, mayor.\\nphysician, editor;\n",
      "1298          YOUNG, Joseph A., Jr., editor, publisher;\n",
      "1299  YOUNG, Joseph Franklin, city councilman, real ...\n",
      "1300      YOUNQ, Nathan Benjamin, college iJapresident;\n",
      "\n",
      "[1301 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"GENTRY, Emery Marcus, teacher; born at Winchester, Ky., Oct. 14, 1880; son of Jacob and Amelia , (Barnes) Gentry; ed. public schools ' in Clark County, and Berea College,\\n' Ky.; B.S., Fisk Univ., Nashville, Tenn., 1905; attended Univ. of Mich., summer school; married Mary . Frankie Whaley, of Maysville, Ky.,\\n: June 22, 1910; 2 children: Annamelia,\\n: Emery, Jr. Teacher in Clark County, i Ky., 18981903, at Mays Lick, 19058;\\n) principal Western High School, Paris, ; Ky., 190810, at 11th Street School, 1 Portsmouth, O., since 1910. Republi-i can. Baptist. Address: 1312 Kinny t St., Portsmouth, Ohio.\\n3 \""
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pattern: 1st name is all caps, following names are not\n",
    "# eg. JOHN, James, physician; born in/at \n",
    "\n",
    "# find all names + occupations\n",
    "# try to include uncaptured 3 letter first names manually\n",
    "name_occ_list = re.findall(r\"(?:[A-Z(?:Mc)']{4,}|COX|RAY|BUM|ISH|POE|LEE)[\\.,; ][ ]?[A-Z'\\(\\)][\\s\\S]+?[;:]\", segment)\n",
    "\n",
    "print(len(name_occ_list))\n",
    "print(pd.DataFrame(name_occ_list))\n",
    "\n",
    "# split base string into a list of strings, each starting with person name\n",
    "\n",
    "# format names into name|name1|name2|...\n",
    "name_template = \"({})\".format(\"|\".join(re.escape(s) for s in name_occ_list))\n",
    "\n",
    "# split base string based on names\n",
    "segment_split = re.split(name_template, segment) \n",
    "\n",
    "# join back the names to the front of each string\n",
    "bio_split = [\"\".join(x) for x in itertools.zip_longest([\"\"] + segment_split[1::2], segment_split[::2], fillvalue='')]\n",
    "\n",
    "bio_split[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract required data from each person's string into a list of dictionaries\n",
    "bio_data = []\n",
    "for i, person in enumerate(bio_split[1:]): # 0th element is unnecessary\n",
    "    \n",
    "    bio_dict = {}\n",
    "\n",
    "    # name and occupation\n",
    "    # occ always starts with lower caps, in contrast to names\n",
    "    occ = re.search(r\"(?<=,)[ ]?[^A-Z0-9]+?[;:]\", name_occ_list[i]) \n",
    "    if occ is not None:\n",
    "        # strip irrelevant chars from sides, then replace any remaining \\n within string\n",
    "        bio_dict[\"occ\"] = occ.group().strip(\"-–—\\n ,;:'\").replace(\"\\n\",\" \") \n",
    "    else:\n",
    "        bio_dict[\"occ\"] = None\n",
    "    \n",
    "    # name\n",
    "    # search for repeating groups with first letter capitalized\n",
    "    name = re.search(r\"^(?:[A-Z][A-Za-z\\. \\(\\)]+,[ ]?)+\", name_occ_list[i]) # might need to edit pattern\n",
    "    if name is not None:\n",
    "        bio_dict[\"name\"] =  name.group().strip(\"-–—\\n ,;:\").replace(\"\\n\",\" \")\n",
    "    else:\n",
    "        bio_dict[\"name\"] = None # can change this later: this is causing a few blank names in csv\n",
    "    \n",
    "    # birth details: birthdate and birthplace\n",
    "    # don't capture preceding \"born at/in...\"\n",
    "    birthdetails = re.search(r\"(?:born|bom)[\\s\\S]*?([A-Z][\\s\\S]+?);\", person) \n",
    "    if birthdetails is not None:\n",
    "        # date of birth + place of birth\n",
    "        birthdate = re.search(r\"[A-Z][a-z]{2,3}[\\., ]+?\\d+[,\\.][\\., ]+?\\d{4}\", birthdetails.group(1))\n",
    "        if birthdate is not None:\n",
    "            bio_dict[\"birthdate\"] = birthdate.group().replace(\"\\n\",\" \")\n",
    "            # remove birthdate from birthdetails string by taking first item after split\n",
    "            bio_dict[\"birthplace\"] = birthdetails.group(1).split(birthdate.group())[0].strip(\" :;, }{'\\\\<13\\^)(\").replace(\"\\n\",\" \")\n",
    "        else:\n",
    "            bio_dict[\"birthdate\"] = None\n",
    "            bio_dict[\"birthplace\"] = None  \n",
    "    else:\n",
    "        bio_dict[\"birthdate\"] = None\n",
    "        bio_dict[\"birthplace\"] = None \n",
    "    \n",
    "    # address\n",
    "    # permutations: Home: OR Home and office: OR Home: Office: OR Home: Address: OR Address:\n",
    "    \n",
    "    # first check for 2 locations: Home:...Office: OR Home:...Address:\n",
    "    dual_addresses = re.search(r\"Home[:;]([\\s\\S]+?)(?:Office|Address|office|address)[:;]([\\s\\S]+)\", person)\n",
    "    # if 2 addresses\n",
    "    if dual_addresses is not None:\n",
    "        # curaddress = office/address \n",
    "        # residence = home\n",
    "        bio_dict[\"curaddress\"] = dual_addresses.group(1).replace(\"\\n\",\" \").strip(\" \")\n",
    "        bio_dict[\"residence\"] = dual_addresses.group(2).replace(\"\\n\",\" \").strip(\" \")\n",
    "    else:\n",
    "        # else check for single location\n",
    "        # assume location to be home residence\n",
    "        bio_dict[\"curaddress\"] = None\n",
    "        address = re.search(r\"(?:Home and office|Address|Home)[:;]([\\s\\S]+)\", person)\n",
    "        if address is not None:\n",
    "            bio_dict[\"residence\"] = address.group(1).replace(\"\\n\",\" \").strip(\" \")\n",
    "        else:\n",
    "            bio_dict[\"residence\"] = None\n",
    "    \n",
    "    bio_data.append(bio_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning + formatting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "biodf = pd.DataFrame(bio_data).fillna('')\n",
    "\n",
    "# format/rearrange df columns\n",
    "biodf.columns.values\n",
    "biodf = biodf[['name', 'birthplace', 'birthdate', 'occ', 'curaddress', 'residence']]\n",
    "biodf.index.name = \"persid\"\n",
    "\n",
    "# correct Illinois OCR errors\n",
    "illinois_errors = [',[ ]?[iI1lL]{3}[\\.]?', ',[ ]?[HLDnU][iI1lL]\\.', ',[ ]?IUL\\.', ',[ ]?m.', ',[ ]?IU']\n",
    "biodf['curaddress'] = biodf['curaddress'].replace(to_replace = illinois_errors, value = ', Ill.', regex = True)\n",
    "biodf['residence'] = biodf['residence'].replace(to_replace = illinois_errors, value = ', Ill.', regex = True)\n",
    "biodf['birthplace'] = biodf['birthplace'].replace(to_replace = illinois_errors, value = ', Ill.', regex = True)\n",
    "\n",
    "# correct New York errors\n",
    "biodf['curaddress'] = biodf['curaddress'].replace('New Yorl', 'New York')\n",
    "biodf['residence'] = biodf['residence'].replace('New Yorl', 'New York')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'(', ')'}\n"
     ]
    }
   ],
   "source": [
    "# cleaning dataframe: name\n",
    "\n",
    "# convert name col to combined string\n",
    "name_string = ''.join(biodf['name'].tolist())\n",
    "non_letters = re.findall(\"[^a-zA-Z,\\. ]\", name_string)\n",
    "print(set(non_letters))\n",
    "\n",
    "# find all names with 0,1,8\n",
    "biodf[biodf['name'].str.contains(r'[0138]')]\n",
    "# replace 1 with I\n",
    "biodf['name'] = biodf['name'].str.replace(\"1\", \"I\")\n",
    "# replace 0 with O\n",
    "biodf['name'] = biodf['name'].str.replace(\"0\", \"O\")\n",
    "# replace 8 with S\n",
    "biodf['name'] = biodf['name'].str.replace(\"8\", \"S\")\n",
    "# replace (3 with GI\n",
    "biodf['name'] = biodf['name'].str.replace(\"\\(3\", \"GI\")\n",
    "# remove *\n",
    "biodf['name'] = biodf['name'].str.replace(\"*\", \"\")\n",
    "# remove names with WHO'S WHO IN \n",
    "biodf['name'] = biodf['name'].str.replace(\"WHO'S WHO IN \", \"\")\n",
    "\n",
    "# no maiden names to extract\n",
    "\n",
    "# extract out miscaptured occ strings in name and add to occ\n",
    "# remove miscaptured b. strings first\n",
    "biodf[\"name\"] = biodf[\"name\"].str.replace(\";b\\.\", \"\")\n",
    "biodf.loc[biodf['name'].str.contains(r\"; [\\s\\S]+\"), 'occ'] = (biodf.loc[biodf['name'].str.contains(r\"; [\\s\\S]+\"), 'name'].str.extract(r\"; ([\\s\\S]+)\", expand=False) + \", \") + biodf.loc[biodf['name'].str.contains(r\"; [\\s\\S]+\"), 'occ'].astype(str)\n",
    "biodf[\"name\"] = biodf[\"name\"].str.replace(\";.*\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>birthplace</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>occ</th>\n",
       "      <th>curaddress</th>\n",
       "      <th>residence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, birthplace, birthdate, occ, curaddress, residence]\n",
       "Index: []"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning dataframe: occ\n",
    "biodf[biodf['occ'].str.contains('[^A-Za-z\\., -]')] \n",
    "for char in ['►', '\\*', '\\$', 'c/o', '\\^', '\\|', '\\?', '\\([\\s\\S]+?\\)', '■', '<', '\\)', '~', '\\\"', '%', '!', r'\\\\', '#', '- > ', '->', '_', '\\'', '[', ']', '>', '{', '}', '&']:\n",
    "    biodf['occ'] = biodf['occ'].str.replace(char, \"\")\n",
    "    \n",
    "# replace any resultant double spaces\n",
    "biodf['occ'] = biodf['occ'].str.replace(\"  \", \" \")\n",
    "\n",
    "biodf[biodf['occ'].str.contains('[^A-Za-z\\., -]')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ala\\.|Ala\\.|Alaska\\.|Alaska\\.|Alas\\.|Ariz\\.|Ariz\\.|Az\\.|Ark\\.|Ark\\.|Calif\\.|Calif\\.|Ca\\.|Cal\\.|Colo\\.|Colo\\.|Conn\\.|Conn\\.|Ct\\.|Del\\.|Del\\.|De\\.|D\\.C\\.|D\\. C\\.|Wash\\. D\\.C\\.|Fla\\.|Fla\\.|Fl\\.|Flor\\.|Ga\\.|Ga\\.|Hawaii\\.|Hawaii\\.|H\\.I\\.|Idaho\\.|Idaho\\.|Id\\.|Ida\\.|Ill\\.|Ill\\.|Il\\.|Ills\\.|Ill's\\.|Ind\\.|Ind\\.|In\\.|Iowa\\.|Iowa\\.|Ia\\.|Ioa\\.|Kans\\.|Kan\\.|Ks\\.|Ka\\.|Ky\\.|Ky\\.|Ken\\.|Kent\\.|La\\.|La\\.|Maine\\.|Maine\\.|Me\\.|Md\\.|Md\\.|Mass\\.|Mass\\.|Mich\\.|Mich\\.|Minn\\.|Minn\\.|Mn\\.|Miss\\.|Miss\\.|Mo\\.|Mo\\.|Mont\\.|Mont\\.|Nebr\\.|Neb\\.|Nev\\.|Nev\\.|Nv\\.|N\\.H\\.|N\\. H\\.|N\\.J\\.|N\\. J\\.|N\\. Jersey\\.|N\\. Mex\\.|N\\. M\\.|New M\\.|N\\.Y\\.|N\\. Y\\.|N\\. York\\.|N\\. Y\\.|N\\.C\\.|N\\. C\\.|N\\. Car\\.|N\\. Dak\\.|N\\. D\\.|NoDak\\.|N\\.Dak\\.|Ohio\\.|Ohio\\.|Oh\\.|Okla\\.|Okla\\.|Ok\\.|Oreg\\.|Ore\\.|Or\\.|Pa\\.|Pa\\.|Penn\\.|Penna\\.|R\\.I\\.|R\\. I\\.|R I\\. \\.|R\\. Isl\\.|R\\.Isl\\.|S\\.C\\.|S\\. C\\.|S\\. Car\\.|S\\. Dak\\.|S\\. D\\.|SoDak\\.|S\\.Dak\\.|Tenn\\.|Tenn\\.|Tex\\.|Texas\\.|Tx\\.|Utah\\.|Utah\\.|Ut\\.|Vt\\.|Vt\\.|Va\\.|Va\\.|Virg\\.|Wash\\.|Wash\\.|Wa\\.|Wn\\.|W\\. Va\\.|W\\.Va\\.|W\\.V\\.|W\\. Virg\\.|W\\.Virg\\.|Wis\\.|Wis\\.|Wi\\.|Wisc\\.|Wyo\\.|Wyo\\.|Wy\\.|Ont\\.\n"
     ]
    }
   ],
   "source": [
    "# read state name csv\n",
    "os.chdir(r\"C:\\Users\\byron\\OneDrive\\Documents\\University\\US\\NYU\\SPUR\\WIW\")\n",
    "statedf = pd.read_csv(\"state_names.csv\")\n",
    "\n",
    "# create state abbreviation list\n",
    "state_abbs = statedf[[\"SNAME1\", \"SNAME2\", \"SNAME3\", \"SNAME4\", \"SNAME5\"]].stack().reset_index()[0].tolist()\n",
    "state_abbs.remove(\"O.\") # remove problematic abbreviation (in this case, output is unaffected)\n",
    "\n",
    "# add . to any state abbreviation not ending with . to avoid false match\n",
    "state_abbs_new = [abb + \".\" if abb[-1] != \".\" else abb for abb in state_abbs ]\n",
    "        \n",
    "# formulate regex argument\n",
    "state_abbs_string = \"|\".join(state_abbs_new).replace(\".\", \"\\.\")\n",
    "print(state_abbs_string)\n",
    "\n",
    "# cut address/residence to state \n",
    "# note that this might cut addresses with state abbreviations at start of address\n",
    "# only alter matches with state name in string\n",
    "\n",
    "# curaddress\n",
    "biodf.loc[biodf['curaddress'].str.len() > 200, 'curaddress'] = biodf.loc[biodf['curaddress'].str.len() > 200, 'curaddress'].str.extract(rf\"(^[\\s\\S]*?(?:{state_abbs_string}))\", expand=False)\n",
    "# residence is messier, requires more cleaning\n",
    "biodf.loc[biodf['residence'].str.contains(rf\"{state_abbs_string}\"), 'residence'] = biodf.loc[biodf['residence'].str.contains(rf\"{state_abbs_string}\"), 'residence'].str.extract(rf\"(^[\\s\\S]*?(?:{state_abbs_string}))\", expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'(', '\"', '|', '^', '!', '>', ':', '$', ']', '&', ')', '\\\\', '?', ';', '<'}\n",
      "{'^', '%', '_', '\\\\', ';', '<', ')', '(', '/', '\\ufeff', '>', '?', '\"', '|', '!', ':', '$', '&', ']'}\n"
     ]
    }
   ],
   "source": [
    "# find invalid letters from combined string of address and residence\n",
    "address_string = ''.join(biodf['curaddress'].astype(str).tolist())\n",
    "non_letters = re.findall(r\"[^a-zA-Z,\\. 0-9\\-\\']\", address_string)\n",
    "print(set(non_letters))\n",
    "\n",
    "residence_string = ''.join(biodf['residence'].astype(str).tolist())\n",
    "non_letters = re.findall(r\"[^a-zA-Z,\\. 0-9\\-\\']\", residence_string)\n",
    "print(set(non_letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'(', '>', ':', '&', ';'}\n",
      "{'(', '/', '>', ':', '\\ufeff', '&', ';'}\n"
     ]
    }
   ],
   "source": [
    "# replace all redundant chars\n",
    "for char in ['►', '\\*', '\\$', 'c/o', '\\^', '\\|', '\\?', '\\([\\s\\S]+?\\)', '■', '<', '\\)', '~', '\\\"', '%', '!', r'\\\\', '#', '- > ', '_']: \n",
    "    biodf['curaddress'] = biodf['curaddress'].str.replace(char, \"\")\n",
    "    biodf['residence'] = biodf['residence'].str.replace(char, \"\")\n",
    "\n",
    "biodf['curaddress'] = biodf['curaddress'].str.replace(\"\\]\", \"l\")\n",
    "biodf['residence'] = biodf['residence'].str.replace(\"\\]\", \"l\")\n",
    "\n",
    "# find the remaining list of non letters\n",
    "address_string = ''.join(biodf['curaddress'].astype(str).tolist())\n",
    "non_letters = re.findall(r\"[^a-zA-Z,\\. 0-9\\-\\']\", address_string)\n",
    "print(set(non_letters))\n",
    "\n",
    "address_string = ''.join(biodf['residence'].astype(str).tolist())\n",
    "non_letters = re.findall(r\"[^a-zA-Z,\\. 0-9\\-\\']\", address_string)\n",
    "print(set(non_letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                                         DETT, R. Nathaniel\n",
       "birthplace                                                     \n",
       "birthdate                                                      \n",
       "occ                                          composer,t pianist\n",
       "curaddress                 362 Second St., Niagara Falls, N. Y.\n",
       "residence     Hampton Normal and Agricultural Institute, Ham...\n",
       "Name: 407, dtype: object"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biodf = biodf.fillna(\"\")\n",
    "# replace all double spaces with single space\n",
    "biodf = biodf.replace(\"  \", \" \")\n",
    "\n",
    "# strip any spaces \n",
    "for col in ['name', 'birthplace', 'birthdate', 'occ', 'curaddress', 'residence']:\n",
    "    biodf[col] = biodf[col].str.strip(\" \")\n",
    "\n",
    "biodf.iloc[407]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the names easier for matching by expanding the commonly used acronyms \n",
    "\n",
    "# Make a list of common states acronyms (N.Y. is New York) from a csv file. Store it as dictionary.\n",
    "state_acron={}\n",
    "with open('state_names_expanded_2.csv', mode='r') as infile:\n",
    "    # skip the first line (header)\n",
    "    infile.readline()\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        for i in range(5):\n",
    "            if row[i] != \"\": state_acron[row[i]]=row[5]\n",
    "\n",
    "# Sometimes it's \"N Y University\", not \"N.Y. University\" in the data\n",
    "# So next we create the same dictionary of states but without dots. \n",
    "    state_acron_no_dots={}\n",
    "    with open('state_names_expanded_2.csv', mode='r') as infile:\n",
    "        infile.readline()\n",
    "        reader = csv.reader(infile)\n",
    "        for row in reader:\n",
    "            for i in range(5):\n",
    "                row[i] = re.sub(\"\\.\", \"\", row[i]) \n",
    "                if row[i] != \"\": state_acron_no_dots[row[i]]=row[5]                \n",
    "\n",
    "# create a function that expands the acronyms for a given column \n",
    "def expand_acronyms(list_institutions):\n",
    "    # Define the regex patterns before looping\n",
    "    pattern1 = re.compile(r'\\b(' + '|'.join(sorted(re.escape(k) for k in state_acron)) + r')\\b')\n",
    "    pattern2 = re.compile(r'(\\s|,|^)(' + '|'.join(re.escape(key) for key in state_acron_no_dots.keys()) + r')(\\s|,|$)')\n",
    "    # use the state acronyms dictionary to expand the names to the full ones.\n",
    "    list_institutions_return = list_institutions.copy()\n",
    "    for i, place in enumerate(list_institutions):\n",
    "        if place:\n",
    "            # there is no need to care about the acronyms being separate words, \n",
    "            # because at this point the acronyms in the dictionary always have dots.\n",
    "            place = re.sub(pattern1, lambda m: state_acron.get(m.group(0)), place)\n",
    "            #### use the acronym dictionary to make changes\n",
    "            place = re.sub('\\.', ' ', place)\n",
    "            place = re.sub(\"[\\(\\)]\", \"\", place)\n",
    "            #remove multiple spaces and change \"U S\" -> \"US\", \"Poly tech\" -> \"Polytech\", \"De Paul/w\" -> \"DePaul/w\"\n",
    "            place = re.sub(r'\\s+', ' ', place)\n",
    "            place = place.replace('U S', \n",
    "                                  'US')\n",
    "\n",
    "            #### finally, use the state dictionary without dots\n",
    "    \n",
    "            # use the dictionary of state acronyms to clean the list\n",
    "            place = re.sub(pattern2, lambda m: \" \" + state_acron_no_dots.get(m.group(0).strip(' ,')) + \" \", place)\n",
    "            #remove double, triple etc spaces\n",
    "            place = re.sub(r'\\s+', ' ', place).strip(' ,')\n",
    "            #remove spaces before commas\n",
    "            place = re.sub(r' ,', ',', place)\n",
    "            #### \"Nat. Sciences\" is \"Natural Sciences\", but in all other cases \"Nat\" means \"National\".  \n",
    "            place = re.sub('Nat Sci', 'Natural Sci', place)\n",
    "            place = re.sub('Nat\\s', 'National ', place)\n",
    "            list_institutions_return[i] = place\n",
    "#             if i<15 or i>82150:\n",
    "#                 print(i, place, list_institutions[i])\n",
    "    return(list_institutions_return)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# replace NaN values for empty cells with an empty string\n",
    "biodf = biodf.fillna(\"\")\n",
    "\n",
    "# clean birthplace column\n",
    "# some entries have stray commas/periods with single letters following\n",
    "biodf['birthplace'] = biodf['birthplace'].str.replace(r\"[.,][ ]?[a-z][\\s\\S]*\", \"\", regex=True)\n",
    "\n",
    "# expand birthplace column state names\n",
    "bp_expanded = expand_acronyms(list(biodf['birthplace']))\n",
    "biodf['birthplace_exp'] = bp_expanded\n",
    "biodf = biodf[['name', 'birthplace', 'birthplace_exp', 'birthdate', 'occ', 'curaddress', 'residence']]    \n",
    "\n",
    "# cities with missing states usually have their states miscaptured in birthdate string\n",
    "# for entries with expanded birthplace = birthplace AND state abb in birthdate, extract out state to birthplace\n",
    "biodf.loc[(biodf[\"birthplace\"] == biodf[\"birthplace_exp\"]) & (biodf[\"birthdate\"].str.contains(rf\"{state_abbs_string}\")), \"birthplace\"] += \", \" + biodf.loc[(biodf[\"birthplace\"] == biodf[\"birthplace_exp\"]) & (biodf[\"birthdate\"].str.contains(rf\"{state_abbs_string}\")), \"birthdate\"].str.extract(rf\"({state_abbs_string})\", expand=False)\n",
    "# remove state abb from birthdate and clean entry\n",
    "biodf.loc[biodf[\"birthdate\"].str.contains(rf\"{state_abbs_string}\"), \"birthdate\"] = biodf.loc[biodf[\"birthdate\"].str.contains(rf\"{state_abbs_string}\"), \"birthdate\"].str.replace(rf\"{state_abbs_string}\", \"\")\n",
    "biodf.loc[biodf[\"birthdate\"].str.contains(rf\"{state_abbs_string}\"), \"birthdate\"] = biodf.loc[biodf[\"birthdate\"].str.contains(rf\"{state_abbs_string}\"), \"birthdate\"].str.strip(\" ,.\")\n",
    "\n",
    "# again, expand birthplace column state names\n",
    "bp_expanded = expand_acronyms(list(biodf['birthplace']))\n",
    "biodf['birthplace_exp'] = bp_expanded\n",
    "biodf = biodf[['name', 'birthplace', 'birthplace_exp', 'birthdate', 'occ', 'curaddress', 'residence']] \n",
    "\n",
    "# further expand unrecognized abbreviations/errors\n",
    "missed_abbs = {r'W[Iil][Ss]': \"Wisconsin\", \n",
    "                   \"Maas\": \"Massachusetts\", \n",
    "                       \"British West Indes\": \"British West Indies\",\n",
    "                       \"Miss/\": \"Mississippi\",\n",
    "                          \"Coon\": \"Connecticut\",\n",
    "                              \"fey\": \"Kentucky\",\n",
    "                                  \"8 C\": \"South Carolina\",\n",
    "                                    \"N \\^ C\": \"North Carolina\",\n",
    "                                        \"N > C\": \"North Carolina\",\n",
    "                                        r\",[ ]?IN C\\b\": \", North Carolina\",\n",
    "                                          r\",[ ]?la\": \", Iowa\",\n",
    "                                            r\",[ ]?ky\": \", Kentucky\",\n",
    "                                               r\",[ ]?Kjr\": \", Kentucky\",\n",
    "                                                   r\",[ ]?Xy\": \", Kentucky\",\n",
    "                                                       r\",[ ]?Da\": \", Georgia\",\n",
    "                                                           \"G&\": \"Georgia\",\n",
    "                                                               \"V&\": \"Virginia\",\n",
    "                                                                   r\"Virginia, I\\b\": \"Virginia\",\n",
    "                                                                   \"M&\": \"Maryland\",\n",
    "                                                                      r\"Col$\": \"Colorado\",\n",
    "                                                                          \"Teim\": \"Tennessee\",\n",
    "                                                                           \"TeniL\": \"Tennessee\",\n",
    "                                                                               \"Term\": \"Tennessee\",\n",
    "                                                                                   \"Tenm\": \"Tennessee\",\n",
    "                                                                                    \"Tenn'\": \"Tennessee\",\n",
    "                                                                                       \"Tenth\": \"Tennessee\",\n",
    "                                                                                          \"N T\": \"New York\",\n",
    "                                                                                              \"Mb\": \"Missouri\",\n",
    "                                                                                                   r\",[ ]?0\": \", Ohio\",\n",
    "                                                                                                    \"Ohio I I\": \"Ohio\",\n",
    "                                                                                                      \"Tez\": \"Texas\"}\n",
    "# expand these missed abbreviations\n",
    "biodf['birthplace_exp'] = biodf['birthplace_exp'].replace(missed_abbs, regex=True)  \n",
    "    \n",
    "# remove remaining -s\n",
    "# this will alter a few words where - was actually intended\n",
    "biodf['birthplace_exp'] = biodf['birthplace_exp'].str.replace(r\"[ ]*-[ ]*\", \"\", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alberta|British Columbia|Manitoba|New Brunswick|Newfoundland and Labrador|Northwest Territories|Nova Scotia|Ontario|Prince Edward Island|Quebec|Saskatchewan|Alabama|Alaska|Arizona|Arkansas|California|Canada|Colorado|Connecticut|Delaware|District of Columbia|Florida|FOREIGN|Puerto Rico|US Virgin Islands|Georgia|Hawaii|Idaho|Illinois|Indiana|Iowa|Kansas|Kentucky|Louisiana|Maine|Maryland|Massachusetts|Michigan|Minnesota|Mississippi|Missouri|Montana|Nebraska|Nevada|New Hampshire|New Jersey|New Mexico|New York|North Carolina|North Dakota|Ohio|Oklahoma|Oregon|Pennsylvania|Rhode Island|South Carolina|South Dakota|Tennessee|Texas|Utah|Vermont|West Virginia|Virginia|Washington|Wisconsin|Wyoming|Yukon|Guam|American Samoa\n"
     ]
    }
   ],
   "source": [
    "# split birthplace_exp into location and state name\n",
    "\n",
    "# use expanded state name csv\n",
    "expstate_df = pd.read_csv(\"state_names_expanded_2.csv\").fillna(\"\")\n",
    "\n",
    "# function that returns uniques from list (in order)\n",
    "def unique(sequence):\n",
    "    seen = set()\n",
    "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
    "\n",
    "# create state name list, also remove duplicates\n",
    "state_names = unique(list(expstate_df[\"FULLSNAME\"]))\n",
    "        \n",
    "# formulate regex argument\n",
    "state_names_string = \"|\".join(state_names)\n",
    "print(state_names_string)\n",
    "\n",
    "# first extract only state name\n",
    "biodf['birthplace_st'] = biodf['birthplace_exp'].str.extract(fr\"\\b({state_names_string})\\b$\")\n",
    "\n",
    "# then extract only the string before state name (anything behind is removed) by splitting birthplace_exp using birthplace_st\n",
    "# in this case note that FOREIGN state names apply to all outside US/Canada\n",
    "# FOREIGN states will have varying formats in birthplace_loc and birthplace_st due to varying foreign birthplace formats in dataset\n",
    "biodf['birthplace_loc'] = biodf.apply(lambda row : re.split(str(row['birthplace_st']), str(row['birthplace_exp']))[0], axis=1).str.strip(', ')\n",
    "\n",
    "biodf = biodf[['name', 'birthplace', 'birthplace_exp', 'birthplace_loc', 'birthplace_st', 'birthdate', 'occ', 'curaddress', 'residence']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of foreign/non-foreign states\n",
    "is_state_foreign = {}\n",
    "with open('state_names_expanded_2.csv', mode='r') as infile:\n",
    "    # skip the first line (header)\n",
    "    infile.readline()\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        if row[5] != \"\": is_state_foreign[row[5]] = (row[8])\n",
    "\n",
    "# note the definition for FOREIGN column\n",
    "# 0: US states, including US territories\n",
    "# 1: foreign states, including Canada\n",
    "# people without recorded birthplaces have empty entry\n",
    "biodf['FOREIGN'] = biodf['birthplace_st'].map(is_state_foreign) \n",
    "biodf = biodf[['name', 'birthplace', 'birthplace_loc', 'birthplace_st', 'FOREIGN', 'birthdate', 'occ', 'curaddress', 'residence']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit all columns to 100 characters\n",
    "biodf = biodf.apply(lambda x: x.str.slice(0, 100))\n",
    "\n",
    "# further limit all columns except curaddress and residence to 70 characters\n",
    "biodf[['name', 'birthplace', 'birthplace_loc', 'birthplace_st', 'FOREIGN', 'birthdate', 'occ']] = biodf[['name', 'birthplace', 'birthplace_loc', 'birthplace_st', 'FOREIGN', 'birthdate', 'occ']].apply(lambda x: x.str.slice(0, 70)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "os.chdir(r\"C:\\Users\\byron\\OneDrive\\Documents\\University\\US\\NYU\\SPUR\\WIW\")\n",
    "biodf.to_csv('1915_bio_data_2.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking state count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count how many times a state appears in birthplace_st col\n",
    "# original dataframe is sorted by count\n",
    "state_count_df = biodf['birthplace_st'].value_counts().to_frame()\n",
    "state_count_df = state_count_df.rename(columns = {\"birthplace_st\": \"Count\"})\n",
    "state_count_df.index.name = \"State\"\n",
    "\n",
    "# for now, this is sorted alphabetically, not by count\n",
    "# for the sake of counting, Canadian states have been separated out of FOREIGN states\n",
    "state_count_df.sort_index() # remove this line if you want alphabetical order\n",
    "state_count_df.to_csv('1915_state_count.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of people retrieved from main text: 1301\n"
     ]
    }
   ],
   "source": [
    "# checking script output\n",
    "print(\"Total number of people retrieved from main text:\", len(biodf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
