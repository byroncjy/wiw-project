{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 3.7.6\n",
    "import re # version 2.2.1\n",
    "import itertools\n",
    "import os\n",
    "import pandas as pd # version 1.0.1\n",
    "import csv # version 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to ocr_split folder\n",
    "os.chdir(r\"C:\\Users\\byron\\Dropbox\\WIW\\1950_WIW\\ocr_split\")\n",
    "\n",
    "# different cleaning for specific files\n",
    "segment=\"\"\n",
    "for file in os.listdir():\n",
    "    file_string = open(r\"{}\".format(file), \"r\", encoding=\"utf8\").read()\n",
    "    \n",
    "    # remove redundant strings and certain non-ASCII chars\n",
    "    for apos in [\"‘\", \"’\"]:\n",
    "        file_string = file_string.replace(apos, \"\\'\")\n",
    "    \n",
    "    for apos in [\"“\", \"”\"]:\n",
    "        file_string = file_string.replace(apos, \"\\\"\")\n",
    "        \n",
    "    file_string = file_string.replace(\"..\", \".\")\n",
    "    file_string = file_string.replace(\"  \", \" \")\n",
    "    file_string = file_string.replace(\"—\", \"-\")\n",
    "    \n",
    "    for string in [\"Digitized by\", \"UNIVERSITY OF MICHIGAN\", \"Original from\", \"-\\n\", \"_\\n\", \"«\", \"»\", \"•\", \"□\", \"°\", \"£\", \"\\t\"]:\n",
    "        file_string = file_string.replace(string, \"\")\n",
    "    \n",
    "    # catch and remove possible photo header formats \\nNAME\\n\n",
    "    photo_names_1 = re.findall(r\"\\n[A-Z]{4,} [A-Z]\\.?(?:[ ]?[A-Z]\\.?)? [A-Z]{4,}\\n\", file_string) #catches JOHN C[.][ K.] DOEL\n",
    "    photo_names_2 = re.findall(r\"\\n[A-Z]{4,}\\.?(?:[ ]?[A-Z]\\.?)? [A-Z]{4,}\\n\", file_string) #catches JOHN[.][ K.] DOEL\n",
    "    photo_names_3 = re.findall(r\"\\n[A-Z]{4,}\\.?(?:[ ]?[A-Z]\\.?)? [A-Z]{4,} [A-Z]{4,}\\n\", file_string) #catches JOHN[.][ K.] DOEL DOEL\n",
    "    photo_names_4 = re.findall(r\"\\n[A-Z]\\.?(?:[ ]?[A-Z]\\.?)? [A-Z]{4,} [A-Z]{4,}\\n\", file_string) #catches J[.][ K.] DOEL DOEL\n",
    "    for photo_name in list(photo_names_1 + photo_names_2 + photo_names_3 + photo_names_4):\n",
    "        file_string = file_string.replace(photo_name, \"\\n\")\n",
    "    \n",
    "    file_string = file_string.replace(\"\\n\\n\", \"\\n\")\n",
    "    \n",
    "    if file == '1950_AB.txt':\n",
    "        # catch and remove photo header formats NAME\\n not starting with A, B\n",
    "        photo_names_5 = re.findall(r\"[A-Z]{4,}[A-Z\\., ]+\\n\", segment)\n",
    "        \n",
    "        for name in photo_names_5:\n",
    "            if name[0] not in \"AB\":\n",
    "                file_string = file_string.replace(name, \"\")\n",
    "    \n",
    "    # for remaining files classified by letter\n",
    "    elif (file !='1950_Z_LATE.txt' and file !='suppl_who_is_who_1950.txt'):\n",
    "        # catch and remove photo header formats NAME\\n not starting with letters in filename + preceding letter\n",
    "        photo_names_5 = re.findall(r\"[A-Z]{4,}[A-Z\\., ]+\\n\", segment)\n",
    "        \n",
    "        # retrieve valid first letters of names from filename\n",
    "        valid_first_letters = re.split(r\"_|\\.\",file)[1]\n",
    "        #include preceding letter\n",
    "        previous_letter = chr(ord(valid_first_letters[0]) - 1)\n",
    "        valid_first_letters = previous_letter + valid_first_letters\n",
    "        \n",
    "        # if name does not start with valid letter, remove it\n",
    "        for name in photo_names_5:\n",
    "            if name[0] not in valid_first_letters:\n",
    "                file_string = file_string.replace(name, \"\")\n",
    "    \n",
    "    # no additional processing for LATE and SUPPL files   \n",
    "    segment += file_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\ufeff'}\n"
     ]
    }
   ],
   "source": [
    "# final check for non-ascii chars\n",
    "rem_ascii = re.findall(\"[^\\x00-\\x7F]\", file_string)\n",
    "print(set(rem_ascii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2789\n",
      "                                                      0\n",
      "0                 ABERNATHY, JOSEPH J., unlv. prof.; b.\n",
      "1     ABRAMS, SAMUEL CHRISTOPHER, clergyman, sch. su...\n",
      "2     ADAMS, ALGER LEROY, clergyman, journalist, soc...\n",
      "3     ADAMS, ALTON AUGUSTUS, naval bandmaster (ret.)...\n",
      "4                 ADAMS, BERNICE WILSON, sales rep.; b.\n",
      "...                                                 ...\n",
      "2784  WILLIAMS, ERNEST YOUNG, physician, prof, med. ...\n",
      "2785  WILLIAMS, IKE, world's lightweight boxing cham...\n",
      "2786  WILLIAMS, NATHANIEL GREENE, coll.prof., musici...\n",
      "2787             WILLIAMSON, CHARLES WESLEY, lawyer; b.\n",
      "2788                 WILSON, EDDIE BYARD, clergyman; b.\n",
      "\n",
      "[2789 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MCDONALD, EDWIN KENNETH, physician; b. Birmingham, Ala., May 7, 1892; s. John H. and Ella (Johnson) McDonald; m. Joanna C. McAdams, 1920; four children: Natalie, Edwin, Jr., William\\nS., John S. A.B., Fisk U., Nashville, Tenn., 1917; M.D., Northwestern U., 1923; further study, pediatrics, under U. of Chicago fellowship, Childrens Memorial Hosp., Chicago, 111. Began practice of med., 1923; has served on staff of Provident Hosp., Chicago; med. examiner, Am. Woodmen, 1930-31; past pres., Cook Co. Physicians Assn.; mem. Elks, Alpha Phi Alpha. Methodist. Address: 5642 S. State St., Chicago, 111.\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all names+occupations\n",
    "name_occ_list = re.findall(r\"[A-Z(?:Mc)']{4,}[\\., ][ ]?[A-Z'\\(\\)].+?[ ;:j]b[\\.,]\", segment)\n",
    "\n",
    "print(len(name_occ_list))\n",
    "print(pd.DataFrame(name_occ_list))\n",
    "\n",
    "# split base string into a list of strings, each starting with person name\n",
    "\n",
    "# format names into name|name1|name2|...\n",
    "name_template = \"({})\".format(\"|\".join(re.escape(s) for s in name_occ_list))\n",
    "\n",
    "# split base string based on names\n",
    "segment_split = re.split(name_template, segment) \n",
    "\n",
    "# join back the names to the front of each string\n",
    "bio_split = [\"\".join(x) for x in itertools.zip_longest([\"\"] + segment_split[1::2], segment_split[::2], fillvalue='')]\n",
    "\n",
    "bio_split[1489]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract required data from each person's string into a list of dictionaries\n",
    "bio_data = []\n",
    "for i, person in enumerate(bio_split[1:]): #0th element unnecessary\n",
    "    \n",
    "    bio_dict = {}\n",
    "\n",
    "    # occupation and name\n",
    "    occ = re.search(r\",[ ]?[^A-Z]+[;:j ](?=b[\\.,])\", name_occ_list[i]) \n",
    "    if occ is not None:\n",
    "        # strip irrelevant chars from sides, then replace any remaining \\n within string\n",
    "        bio_dict[\"occ\"] = occ.group().strip(\"-–—\\n ,;:\").replace(\"\\n\",\" \") \n",
    "    else:\n",
    "        bio_dict[\"occ\"] = None\n",
    "    \n",
    "    # name\n",
    "    if occ is not None:\n",
    "        # remove occupation from name string by taking first item after split\n",
    "        bio_dict[\"name\"] = name_occ_list[i].split(occ.group())[0].replace(\"\\n\",\" \") \n",
    "    else:\n",
    "        # try to find name regardless using pattern\n",
    "        name = re.search(r\"[A-Z\\., (?:Mc)]+(?=,)\", name_occ_list[i])\n",
    "        if name is not None:\n",
    "            bio_dict[\"name\"] =  name.group().replace(\"\\n\",\" \")\n",
    "        else:\n",
    "            bio_dict[\"name\"] = name_occ_list[i]\n",
    "    \n",
    "    # birth details: birthdate and birthplace\n",
    "    birthdetails = re.search(r\"(?<=b\\.).*?;\", person) \n",
    "    if birthdetails is not None:\n",
    "        # date of birth + place of birth\n",
    "        birthdate = re.search(r\"[A-Z][a-zA-Z\\. ]+\\d+[,\\.].*?\\d{4}\", birthdetails.group())\n",
    "        if birthdate is not None:\n",
    "            bio_dict[\"birthdate\"] = birthdate.group().replace(\"\\n\",\" \")\n",
    "            # remove birthdate from birthdetails string by taking first item after split\n",
    "            bio_dict[\"birthplace\"] = birthdetails.group().split(birthdate.group())[0].strip(\";, \").replace(\"\\n\",\" \")\n",
    "        else:\n",
    "            bio_dict[\"birthdate\"] = None\n",
    "            bio_dict[\"birthplace\"] = None  \n",
    "    else:\n",
    "        bio_dict[\"birthdate\"] = None\n",
    "        bio_dict[\"birthplace\"] = None          \n",
    "            \n",
    "    # address\n",
    "    # first check for Business[:]? address:....Home: OR Business[:]? address:...Home address:\n",
    "    business_home_address = re.search(r\"Business[:;]? address[:;]([\\s\\S]+?)Home(?: address)?[:;]([\\s\\S]+)\", person)\n",
    "    # if there are indeed 2 addresses\n",
    "    if business_home_address is not None:\n",
    "        # curaddress = business address, residence = home address\n",
    "        bio_dict[\"curaddress\"] = business_home_address.group(1).replace(\"\\n\",\" \").strip(\" \")\n",
    "        bio_dict[\"residence\"] = business_home_address.group(2).replace(\"\\n\",\" \").strip(\" \")\n",
    "    else:\n",
    "        # next check for Address: or Addresses:\n",
    "        # assume this to be home residence\n",
    "        bio_dict[\"curaddress\"] = None\n",
    "        addresses = re.search(r\"Address(?:es)?[:;]([\\s\\S]+)\", person)\n",
    "        if addresses is not None:\n",
    "            bio_dict[\"residence\"] = addresses.group(1).replace(\"\\n\",\" \").strip(\" \")\n",
    "        else:\n",
    "            bio_dict[\"residence\"] = None\n",
    "    \n",
    "    bio_data.append(bio_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "biodf = pd.DataFrame(bio_data).fillna('')\n",
    "\n",
    "# format/rearrange df columns\n",
    "biodf.columns.values\n",
    "biodf = biodf[['name', 'birthplace', 'birthdate', 'occ', 'curaddress', 'residence']]\n",
    "biodf.index.name = \"persid\"\n",
    "\n",
    "# correct Illinois OCR errors\n",
    "illinois_errors = [',[ ]?[iI1lL]{3}[\\.]?', ',[ ]?[HLDnU][iI1lL]\\.', ',[ ]?IUL\\.', ',[ ]?m.', ',[ ]?IU']\n",
    "biodf['curaddress'] = biodf['curaddress'].replace(to_replace = illinois_errors, value = ', Ill.', regex = True)\n",
    "biodf['residence'] = biodf['residence'].replace(to_replace = illinois_errors, value = ', Ill.', regex = True)\n",
    "biodf['birthplace'] = biodf['birthplace'].replace(to_replace = illinois_errors, value = ', Ill.', regex = True)\n",
    "\n",
    "# correct New York errors\n",
    "biodf['curaddress'] = biodf['curaddress'].replace('New Yorl', 'New York')\n",
    "biodf['residence'] = biodf['residence'].replace('New Yorl', 'New York')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'8', ')', \"'\", '0', '*', '(', '-', ';', '3', '1', '\\ufeff'}\n"
     ]
    }
   ],
   "source": [
    "# cleaning dataframe\n",
    "\n",
    "# convert name col to combined string\n",
    "name_string = ''.join(biodf['name'].tolist())\n",
    "non_letters = re.findall(\"[^a-zA-Z,\\. ]\", name_string)\n",
    "print(set(non_letters))\n",
    "\n",
    "# find all names with -\n",
    "biodf[biodf['name'].str.contains('-')] # from WIW pdf, only #2487 has '-' in name\n",
    "# replace - for all other names\n",
    "biodf.iloc[224]['name'] = biodf.iloc[224]['name'].replace('-', '')\n",
    "biodf.iloc[2249]['name'] = biodf.iloc[2249]['name'].replace('-', '')\n",
    "\n",
    "# find all names with 0,1,8\n",
    "biodf[biodf['name'].str.contains(r'[0138]')]\n",
    "# replace 1 with I\n",
    "biodf['name'] = biodf['name'].str.replace(\"1\", \"I\")\n",
    "# replace 0 with O\n",
    "biodf['name'] = biodf['name'].str.replace(\"0\", \"O\")\n",
    "# replace 8 with S\n",
    "biodf['name'] = biodf['name'].str.replace(\"8\", \"S\")\n",
    "# replace (3 with GI\n",
    "biodf['name'] = biodf['name'].str.replace(\"\\(3\", \"GI\")\n",
    "# remove *\n",
    "biodf['name'] = biodf['name'].str.replace(\"*\", \"\")\n",
    "# remove names with WHO'S WHO IN \n",
    "biodf['name'] = biodf['name'].str.replace(\"WHO'S WHO IN \", \"\")\n",
    "\n",
    "# extract out bracketed names to name_maiden\n",
    "biodf['name_maiden'] = biodf['name'].str.extract(r\"\\(([\\s\\S]+)\\)\")\n",
    "biodf['name_maiden'] = biodf['name_maiden'].str.replace(\"nee \", \"\").replace(\"née \", \"\").replace(\"Mrs.\", \"\")\n",
    "biodf[\"name\"] = biodf[\"name\"].str.replace(r\"\\([\\s\\S]+\\)\", \"\").str.replace(r\"  \", \" \")\n",
    "\n",
    "# extract out miscaptured occ strings in name and add to occ\n",
    "# remove miscaptured b. strings first\n",
    "biodf[\"name\"] = biodf[\"name\"].str.replace(\";b\\.\", \"\")\n",
    "biodf.loc[biodf['name'].str.contains(r\"; [\\s\\S]+\"), 'occ'] = (biodf.loc[biodf['name'].str.contains(r\"; [\\s\\S]+\"), 'name'].str.extract(r\"; ([\\s\\S]+)\", expand=False) + \", \") + biodf.loc[biodf['name'].str.contains(r\"; [\\s\\S]+\"), 'occ'].astype(str)\n",
    "biodf[\"name\"] = biodf[\"name\"].str.replace(\";.*\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ala\\.|Ala\\.|Alaska\\.|Alaska\\.|Alas\\.|Ariz\\.|Ariz\\.|Az\\.|Ark\\.|Ark\\.|Calif\\.|Calif\\.|Ca\\.|Cal\\.|Colo\\.|Colo\\.|Conn\\.|Conn\\.|Ct\\.|Del\\.|Del\\.|De\\.|D\\.C\\.|D\\. C\\.|Wash\\. D\\.C\\.|Fla\\.|Fla\\.|Fl\\.|Flor\\.|Ga\\.|Ga\\.|Hawaii\\.|Hawaii\\.|H\\.I\\.|Idaho\\.|Idaho\\.|Id\\.|Ida\\.|Ill\\.|Ill\\.|Il\\.|Ills\\.|Ill's\\.|Ind\\.|Ind\\.|In\\.|Iowa\\.|Iowa\\.|Ia\\.|Ioa\\.|Kans\\.|Kan\\.|Ks\\.|Ka\\.|Ky\\.|Ky\\.|Ken\\.|Kent\\.|La\\.|La\\.|Maine\\.|Maine\\.|Me\\.|Md\\.|Md\\.|Mass\\.|Mass\\.|Mich\\.|Mich\\.|Minn\\.|Minn\\.|Mn\\.|Miss\\.|Miss\\.|Mo\\.|Mo\\.|Mont\\.|Mont\\.|Nebr\\.|Neb\\.|Nev\\.|Nev\\.|Nv\\.|N\\.H\\.|N\\. H\\.|N\\.J\\.|N\\. J\\.|N\\. Jersey\\.|N\\. Mex\\.|N\\. M\\.|New M\\.|N\\.Y\\.|N\\. Y\\.|N\\. York\\.|N\\. Y\\.|N\\.C\\.|N\\. C\\.|N\\. Car\\.|N\\. Dak\\.|N\\. D\\.|NoDak\\.|N\\.Dak\\.|Ohio\\.|Ohio\\.|Oh\\.|Okla\\.|Okla\\.|Ok\\.|Oreg\\.|Ore\\.|Or\\.|Pa\\.|Pa\\.|Penn\\.|Penna\\.|R\\.I\\.|R\\. I\\.|R I\\. \\.|R\\. Isl\\.|R\\.Isl\\.|S\\.C\\.|S\\. C\\.|S\\. Car\\.|S\\. Dak\\.|S\\. D\\.|SoDak\\.|S\\.Dak\\.|Tenn\\.|Tenn\\.|Tex\\.|Texas\\.|Tx\\.|Utah\\.|Utah\\.|Ut\\.|Vt\\.|Vt\\.|Va\\.|Va\\.|Virg\\.|Wash\\.|Wash\\.|Wa\\.|Wn\\.|W\\. Va\\.|W\\.Va\\.|W\\.V\\.|W\\. Virg\\.|W\\.Virg\\.|Wis\\.|Wis\\.|Wi\\.|Wisc\\.|Wyo\\.|Wyo\\.|Wy\\.|Ont\\.\n"
     ]
    }
   ],
   "source": [
    "# read state name csv\n",
    "os.chdir(r\"C:\\Users\\byron\\OneDrive\\Documents\\University\\US\\NYU\\SPUR\\WIW\")\n",
    "statedf = pd.read_csv(\"state_names.csv\")\n",
    "\n",
    "# create state abbreviation list\n",
    "state_abbs = statedf[[\"SNAME1\", \"SNAME2\", \"SNAME3\", \"SNAME4\", \"SNAME5\"]].stack().reset_index()[0].tolist()\n",
    "state_abbs.remove(\"O.\") # remove problematic abbreviation (in this case, output is unaffected)\n",
    "\n",
    "# add . to any state abbreviation not ending with . to avoid false match\n",
    "state_abbs_new = [abb + \".\" if abb[-1] != \".\" else abb for abb in state_abbs ]\n",
    "        \n",
    "# formulate regex argument\n",
    "state_abbs_string = \"|\".join(state_abbs_new).replace(\".\", \"\\.\")\n",
    "print(state_abbs_string)\n",
    "\n",
    "# cut address/residence to state \n",
    "# note that this might cut addresses with state abbreviations at start of address\n",
    "# only alter matches with state name in string\n",
    "\n",
    "# curaddress almost perfectly accurate, only 2 to be adjusted\n",
    "biodf.loc[biodf['curaddress'].str.len() > 200, 'curaddress'] = biodf.loc[biodf['curaddress'].str.len() > 200, 'curaddress'].str.extract(rf\"(^[\\s\\S]*?(?:{state_abbs_string}))\", expand=False)\n",
    "# residence is messier, requires more cleaning\n",
    "biodf.loc[biodf['residence'].str.contains(rf\"{state_abbs_string}\"), 'residence'] = biodf.loc[biodf['residence'].str.contains(rf\"{state_abbs_string}\"), 'residence'].str.extract(rf\"(^[\\s\\S]*?(?:{state_abbs_string}))\", expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'&', ':', ')', '?', '*', '/', '^', '(', '#', ';', '$', '|', ']', '►'}\n",
      "{'■', '?', '%', '~', '#', '<', ':', ')', '/', '!', '^', '\"', '\\ufeff', '&', '\\\\', '*', '(', ';', '$'}\n"
     ]
    }
   ],
   "source": [
    "# find invalid letters from combined string\n",
    "address_string = ''.join(biodf['curaddress'].astype(str).tolist())\n",
    "non_letters = re.findall(r\"[^a-zA-Z,\\. 0-9\\-\\']\", address_string)\n",
    "print(set(non_letters))\n",
    "\n",
    "address_string = ''.join(biodf['residence'].astype(str).tolist())\n",
    "non_letters = re.findall(r\"[^a-zA-Z,\\. 0-9\\-\\']\", address_string)\n",
    "print(set(non_letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/', '&', ':', ';'}\n",
      "{'&', ':', '/', ';', '\\ufeff'}\n"
     ]
    }
   ],
   "source": [
    "# replace all redundant chars\n",
    "for char in ['►', '\\*', '\\$', 'c/o', '\\^', '\\|', '\\?', '\\([\\s\\S]+?\\)', '■', '<', '\\)', '~', '\\\"', '%', '!', r'\\\\', '#']: \n",
    "    biodf['curaddress'] = biodf['curaddress'].str.replace(char, \"\")\n",
    "    biodf['residence'] = biodf['residence'].str.replace(char, \"\")\n",
    "\n",
    "biodf['curaddress'] = biodf['curaddress'].str.replace(\"\\]\", \"l\")\n",
    "biodf['residence'] = biodf['residence'].str.replace(\"\\]\", \"l\")\n",
    "\n",
    "# find the remaining list of non letters\n",
    "address_string = ''.join(biodf['curaddress'].astype(str).tolist())\n",
    "non_letters = re.findall(r\"[^a-zA-Z,\\. 0-9\\-\\']\", address_string)\n",
    "print(set(non_letters))\n",
    "\n",
    "address_string = ''.join(biodf['residence'].astype(str).tolist())\n",
    "non_letters = re.findall(r\"[^a-zA-Z,\\. 0-9\\-\\']\", address_string)\n",
    "print(set(non_letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                         CARPENTER, MARCUS EDWARD\n",
       "birthplace                                Jersey City\n",
       "birthdate                         N.J. March 21, 1907\n",
       "occ                                         physician\n",
       "curaddress          99 Storms Ave., Jersey City, N.J.\n",
       "residence      253 Monticello Ave., Jersey City, N.J.\n",
       "name_maiden                                          \n",
       "Name: 407, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biodf = biodf.fillna(\"\")\n",
    "# replace all double spaces with single space\n",
    "biodf = biodf.replace(\"  \", \" \")\n",
    "\n",
    "# strip any spaces \n",
    "for col in ['name', 'birthplace', 'birthdate', 'occ', 'curaddress', 'residence', 'name_maiden']:\n",
    "    biodf[col] = biodf[col].str.strip(\" \")\n",
    "\n",
    "biodf.iloc[407]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the names easier for matching by expanding the commonly used acronyms \n",
    "\n",
    "# Make a list of common states acronyms (N.Y. is New York) from a csv file. Store it as dictionary.\n",
    "state_acron={}\n",
    "with open('state_names_expanded_2.csv', mode='r') as infile:\n",
    "    # skip the first line (header)\n",
    "    infile.readline()\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        for i in range(5):\n",
    "            if row[i] != \"\": state_acron[row[i]]=row[5]\n",
    "\n",
    "# Sometimes it's \"N Y University\", not \"N.Y. University\" in the data\n",
    "# So next we create the same dictionary of states but without dots. \n",
    "    state_acron_no_dots={}\n",
    "    with open('state_names_expanded_2.csv', mode='r') as infile:\n",
    "        infile.readline()\n",
    "        reader = csv.reader(infile)\n",
    "        for row in reader:\n",
    "            for i in range(5):\n",
    "                row[i] = re.sub(\"\\.\", \"\", row[i]) \n",
    "                if row[i] != \"\": state_acron_no_dots[row[i]]=row[5]                \n",
    "\n",
    "# create a function that expands the acronyms for a given column \n",
    "def expand_acronyms(list_institutions):\n",
    "    # Define the regex patterns before looping\n",
    "    pattern1 = re.compile(r'\\b(' + '|'.join(sorted(re.escape(k) for k in state_acron)) + r')\\b')\n",
    "    pattern2 = re.compile(r'(\\s|,|^)(' + '|'.join(re.escape(key) for key in state_acron_no_dots.keys()) + r')(\\s|,|$)')\n",
    "    # use the state acronyms dictionary to expand the names to the full ones.\n",
    "    list_institutions_return = list_institutions.copy()\n",
    "    for i, place in enumerate(list_institutions):\n",
    "        if place:\n",
    "            # there is no need to care about the acronyms being separate words, \n",
    "            # because at this point the acronyms in the dictionary always have dots.\n",
    "            place = re.sub(pattern1, lambda m: state_acron.get(m.group(0)), place)\n",
    "            #### use the acronym dictionary to make changes\n",
    "            place = re.sub('\\.', ' ', place)\n",
    "            place = re.sub(\"[\\(\\)]\", \"\", place)\n",
    "            #remove multiple spaces and change \"U S\" -> \"US\", \"Poly tech\" -> \"Polytech\", \"De Paul/w\" -> \"DePaul/w\"\n",
    "            place = re.sub(r'\\s+', ' ', place)\n",
    "            place = place.replace('U S', \n",
    "                                  'US')\n",
    "\n",
    "            #### finally, use the state dictionary without dots\n",
    "    \n",
    "            # use the dictionary of state acronyms to clean the list\n",
    "            place = re.sub(pattern2, lambda m: \" \" + state_acron_no_dots.get(m.group(0).strip(' ,')) + \" \", place)\n",
    "            #remove double, triple etc spaces\n",
    "            place = re.sub(r'\\s+', ' ', place).strip(' ,')\n",
    "            #remove spaces before commas\n",
    "            place = re.sub(r' ,', ',', place)\n",
    "            #### \"Nat. Sciences\" is \"Natural Sciences\", but in all other cases \"Nat\" means \"National\".  \n",
    "            place = re.sub('Nat Sci', 'Natural Sci', place)\n",
    "            place = re.sub('Nat\\s', 'National ', place)\n",
    "            list_institutions_return[i] = place\n",
    "#             if i<15 or i>82150:\n",
    "#                 print(i, place, list_institutions[i])\n",
    "    return(list_institutions_return)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                            CARPENTER, MARCUS EDWARD\n",
       "name_maiden                                             \n",
       "birthplace                             Jersey City, N.J.\n",
       "birthplace_exp                   Jersey City, New Jersey\n",
       "birthdate                                 March 21, 1907\n",
       "occ                                            physician\n",
       "curaddress             99 Storms Ave., Jersey City, N.J.\n",
       "residence         253 Monticello Ave., Jersey City, N.J.\n",
       "Name: 407, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace NaN values for empty cells with an empty string\n",
    "biodf = biodf.fillna(\"\")\n",
    "\n",
    "# expand birthplace column state names\n",
    "bp_expanded = expand_acronyms(list(biodf['birthplace']))\n",
    "biodf['birthplace_exp'] = bp_expanded\n",
    "biodf = biodf[['name', 'name_maiden', 'birthplace', 'birthplace_exp', 'birthdate', 'occ', 'curaddress', 'residence']]    \n",
    "\n",
    "# cities with missing states usually have their states miscaptured in birthdate string\n",
    "# for entries with expanded birthplace = birthplace AND state abb in birthdate, extract out state to birthplace\n",
    "biodf.loc[(biodf[\"birthplace\"] == biodf[\"birthplace_exp\"]) & (biodf[\"birthdate\"].str.contains(rf\"{state_abbs_string}\")), \"birthplace\"] += \", \" + biodf.loc[(biodf[\"birthplace\"] == biodf[\"birthplace_exp\"]) & (biodf[\"birthdate\"].str.contains(rf\"{state_abbs_string}\")), \"birthdate\"].str.extract(rf\"({state_abbs_string})\", expand=False)\n",
    "# remove state abb from birthdate and clean entry\n",
    "biodf.loc[biodf[\"birthdate\"].str.contains(rf\"{state_abbs_string}\"), \"birthdate\"] = biodf.loc[biodf[\"birthdate\"].str.contains(rf\"{state_abbs_string}\"), \"birthdate\"].str.replace(rf\"{state_abbs_string}\", \"\")\n",
    "biodf.loc[biodf[\"birthdate\"].str.contains(rf\"{state_abbs_string}\"), \"birthdate\"] = biodf.loc[biodf[\"birthdate\"].str.contains(rf\"{state_abbs_string}\"), \"birthdate\"].str.strip(\" ,.\")\n",
    "\n",
    "# again, expand birthplace column state names\n",
    "bp_expanded = expand_acronyms(list(biodf['birthplace']))\n",
    "biodf['birthplace_exp'] = bp_expanded\n",
    "biodf = biodf[['name', 'name_maiden', 'birthplace', 'birthplace_exp', 'birthdate', 'occ', 'curaddress', 'residence']] \n",
    "\n",
    "# further expand unrecognized abbreviations/errors\n",
    "missed_abbs = {r'W[Iil][Ss]': \"Wisconsin\", \n",
    "                   \"Maas\": \"Massachusetts\", \n",
    "                       \"Miss/\": \"Mississippi\",\n",
    "                          \"Coon\": \"Connecticut\",\n",
    "                              \"fey\": \"Kentucky\",\n",
    "                                  \"8 C\": \"South Carolina\",\n",
    "                                      r\",[ ]?la\": \", Iowa\",\n",
    "                                          r\"Col$\": \"Colorado\",\n",
    "                                              \"Teim\": \"Tennessee\",\n",
    "                                                  \"N T\": \"New York\",\n",
    "                                                      \"Mb\": \"Missouri\",\n",
    "                                                        \"Term\": \"Tennessee\",\n",
    "                                                          \"Tez\": \"Texas\"}\n",
    "\n",
    "# expand these wrong abbreviations\n",
    "biodf['birthplace_exp'] = biodf['birthplace_exp'].replace(missed_abbs, regex=True)  \n",
    "    \n",
    "# remove remaining -s\n",
    "# this will alter a few words where - was actually intended\n",
    "biodf['birthplace_exp'] = biodf['birthplace_exp'].str.replace(r\"[ ]*-[ ]*\", \"\", regex = True)\n",
    "\n",
    "biodf.iloc[407]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alberta|British Columbia|Manitoba|New Brunswick|Newfoundland and Labrador|Northwest Territories|Nova Scotia|Ontario|Prince Edward Island|Quebec|Saskatchewan|Alabama|Alaska|Arizona|Arkansas|California|Canada|Colorado|Connecticut|Delaware|District of Columbia|Florida|FOREIGN|Puerto Rico|US Virgin Islands|Georgia|Hawaii|Idaho|Illinois|Indiana|Iowa|Kansas|Kentucky|Louisiana|Maine|Maryland|Massachusetts|Michigan|Minnesota|Mississippi|Missouri|Montana|Nebraska|Nevada|New Hampshire|New Jersey|New Mexico|New York|North Carolina|North Dakota|Ohio|Oklahoma|Oregon|Pennsylvania|Rhode Island|South Carolina|South Dakota|Tennessee|Texas|Utah|Vermont|West Virginia|Virginia|Washington|Wisconsin|Wyoming|Yukon|Guam|American Samoa\n"
     ]
    }
   ],
   "source": [
    "# split birthplace_exp into location and state name\n",
    "\n",
    "# use expanded state name csv\n",
    "expstate_df = pd.read_csv(\"state_names_expanded_2.csv\").fillna(\"\")\n",
    "\n",
    "# function that only returns uniques from list (in order)\n",
    "def unique(sequence):\n",
    "    seen = set()\n",
    "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
    "\n",
    "# create state name list, also remove duplicates\n",
    "state_names = unique(list(expstate_df[\"FULLSNAME\"]))\n",
    "        \n",
    "# formulate regex argument\n",
    "state_names_string = \"|\".join(state_names)\n",
    "print(state_names_string)\n",
    "\n",
    "# first extract only state name\n",
    "biodf['birthplace_st'] = biodf['birthplace_exp'].str.extract(fr\"\\b({state_names_string})\\b$\")\n",
    "\n",
    "# then extract only the string before state name (anything behind is removed) by splitting birthplace_exp using birthplace_st\n",
    "# in this case note that FOREIGN state names apply to all outside US/Canada\n",
    "# FOREIGN states will have varying formats in birthplace_loc and birthplace_st due to varying foreign birthplace formats in dataset\n",
    "biodf['birthplace_loc'] = biodf.apply(lambda row : re.split(str(row['birthplace_st']), str(row['birthplace_exp']))[0], axis=1).str.strip(', ')\n",
    "\n",
    "biodf = biodf[['name', 'name_maiden', 'birthplace', 'birthplace_exp', 'birthplace_loc', 'birthplace_st', 'birthdate', 'occ', 'curaddress', 'residence']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of foreign/non-foreign states\n",
    "is_state_foreign={}\n",
    "with open('state_names_expanded_2.csv', mode='r') as infile:\n",
    "    # skip the first line (header)\n",
    "    infile.readline()\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        if row[5] != \"\": is_state_foreign[row[5]] = (row[8])\n",
    "\n",
    "# note the definition for FOREIGN column\n",
    "# 0: US states, including US territories\n",
    "# 1: foreign states, including Canada\n",
    "# people without recorded birthplaces have empty entry\n",
    "biodf['FOREIGN'] = biodf['birthplace_st'].map(is_state_foreign) \n",
    "biodf = biodf[['name', 'name_maiden', 'birthplace', 'birthplace_loc', 'birthplace_st', 'FOREIGN', 'birthdate', 'occ', 'curaddress', 'residence']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit all columns to 100 characters\n",
    "biodf = biodf.apply(lambda x: x.str.slice(0, 100))\n",
    "\n",
    "# further limit all columns except curaddress and residence to 70 characters\n",
    "biodf[['name', 'name_maiden', 'birthplace', 'birthplace_loc', 'birthplace_st', 'FOREIGN', 'birthdate', 'occ']] = biodf[['name', 'name_maiden', 'birthplace', 'birthplace_loc', 'birthplace_st', 'FOREIGN', 'birthdate', 'occ']].apply(lambda x: x.str.slice(0, 70)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "os.chdir(r\"C:\\Users\\byron\\OneDrive\\Documents\\University\\US\\NYU\\SPUR\\WIW\")\n",
    "biodf.to_csv('1950_bio_data_3.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count how many times a state appears in birthplace_st col\n",
    "# original dataframe is sorted by count\n",
    "state_count_df = biodf['birthplace_st'].value_counts().to_frame()\n",
    "state_count_df = state_count_df.rename(columns = {\"birthplace_st\": \"Count\"})\n",
    "state_count_df.index.name = \"State\"\n",
    "\n",
    "# for now, this is sorted alphabetically, not by count\n",
    "# for the sake of counting, Canadian states have been separated out of FOREIGN states\n",
    "state_count_df.sort_index() # remove this line if you want alphabetical order\n",
    "state_count_df.to_csv('1950_state_count.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocations: 122\n"
     ]
    }
   ],
   "source": [
    "# count total per vocation\n",
    "# read vocational index\n",
    "voca_string = open(r\"index_voca.txt\", \"r\", encoding=\"utf8\").read()\n",
    "\n",
    "# clean text string\n",
    "voca_string = re.sub(r\"U\\.[ ]?[8t]\\.\", \"U.S.\", voca_string)\n",
    "for string in [\"Digitized by\", \"Google\", \"UNIVERSITY OF MICHIGAN\", \"Original from\"]:\n",
    "        voca_string = voca_string.replace(string, \"\")\n",
    "voca_string = voca_string.replace(\"  \", \" \")\n",
    "\n",
    "# find all vocations\n",
    "voca_list = re.findall(r\"\\n.*?[A-Z]{4,}.*?\\n\", voca_string)\n",
    "print(\"Number of vocations:\", len(voca_list))\n",
    "\n",
    "# split base string into a list of strings, each starting with voca\n",
    "\n",
    "# format vocas into voca|voca1|name2|...\n",
    "voca_template = \"({})\".format(\"|\".join(re.escape(s) for s in voca_list))\n",
    "\n",
    "# split base string based on vocas\n",
    "voca_split = re.split(voca_template, voca_string) \n",
    "\n",
    "# join back the vocas to the front of each string\n",
    "voca_split = [\"\".join(x) for x in itertools.zip_longest([\"\"] + voca_split[1::2], voca_split[::2], fillvalue='')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of names: 3143\n",
      "Total number of unique people: 2865\n"
     ]
    }
   ],
   "source": [
    "# count per vocation\n",
    "# creates a dataframe with just names, but can be easily edited to include vocation\n",
    "# this can be copied for geographical distribution file as well\n",
    "total = 0\n",
    "name_list = []\n",
    "for voca in voca_split[2:]: #start from first vocation\n",
    "    # format: John, D. OR John, D.O. OR John, D.O.E.\n",
    "    voca_names = re.findall(r\"[A-Z].*?,[ ]?[A-Z0-9]\\.[ ]?[A-Z0-9]?[\\.]?[A-Z0-9]?[\\.]?\", voca)\n",
    "    total += len(voca_names)\n",
    "    df = pd.DataFrame({'name':name_list})\n",
    "    name_list += voca_names\n",
    "\n",
    "print(\"Total number of names:\", total) \n",
    "\n",
    "# sort alphabetically and also account for names being listed under multiple occupations\n",
    "# may exclude rare instances where more than one person has same name and initials\n",
    "name_list = list(set(name_list))\n",
    "name_list.sort()\n",
    "voca_df = pd.DataFrame(name_list)\n",
    "voca_df.columns = [\"name\"]\n",
    "voca_df.index.name = \"persid\"\n",
    "voca_df[\"name\"] = voca_df[\"name\"].str.upper()\n",
    "\n",
    "print(\"Total number of unique people:\", len(name_list))\n",
    "\n",
    "# function to find duplicates\n",
    "def list_duplicates(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    # adds all elements it doesn't know yet to seen and all other to seen_twice\n",
    "    seen_twice = set( x for x in seq if x in seen or seen_add(x) )\n",
    "    # turn the set into a list\n",
    "    return list(seen_twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write name list to csv\n",
    "voca_df.to_csv('1950_voca_names.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of people in main text: 2789\n",
      "Total number of unique people in vocational index: 2865\n",
      "Extraction rate (%): 97.34729493891797\n"
     ]
    }
   ],
   "source": [
    "# verifying script\n",
    "print(\"Total number of people in main text:\", len(biodf))\n",
    "print(\"Total number of unique people in vocational index:\", len(name_list))\n",
    "print(\"Extraction rate (%):\", len(biodf)/len(set(name_list))*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
